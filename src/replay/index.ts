import {
  END,
  START,
  StateGraph,
  Annotation,
  MemorySaver,
} from "@langchain/langgraph";
import model from "../../model";
import { BaseMessage, HumanMessage } from "@langchain/core/messages";
import { RunnableConfig } from "@langchain/core/runnables";
import { createInterface, Interface } from "readline";

async function getGraphBuilder(rl: Interface) {
  const StateAnnotation = Annotation.Root({
    messages: Annotation<BaseMessage[]>,
    interrupted: Annotation<boolean>,
    pending_input: Annotation<string>,
  });

  const interruptNode = async (state: typeof StateAnnotation.State) => {
    const userInput = await new Promise<string>((resolve) => {
      rl.question("\nğŸ›‘ç­”æ¡ˆæ˜¯å¦æ»¡æ„ï¼Ÿ(yes/no): ", resolve);
    });

    return {
      pending_input: userInput.toLowerCase(),
      interrupted: userInput.toLowerCase() !== "yes",
    };
  };

  const chatNode = async (
    state: typeof StateAnnotation.State,
    config?: RunnableConfig
  ) => {
    const { messages } = state;

    const response = await model.invoke(messages, config);
    return { messages: [...messages, response] };
  };

  const printNode = (state: typeof StateAnnotation.State) => {
    const lastMessage = state.messages.slice(-1)[0];
    if ("content" in lastMessage && !(lastMessage instanceof HumanMessage)) {
      console.log(`AIï¼š${lastMessage.content}`);
    }
    return {};
  };

  const feedbackNode = async (state: typeof StateAnnotation.State) => {
    const reason = await new Promise<string>((resolve) => {
      rl.question("âŒ è¯·è¯´æ˜ä½ ä¸æ»¡æ„çš„åŸå› ï¼š", resolve);
    });
    console.log("é‡æ–°ç”Ÿæˆä¸­...");

    return {
      messages: [
        ...state.messages,
        new HumanMessage(`æˆ‘ä¸æ»¡æ„ä½ çš„å›ç­”ï¼Œå› ä¸ºï¼š${reason}`),
      ],
    };
  };

  return new StateGraph(StateAnnotation)
    .addNode("chat", chatNode)
    .addNode("interrupt", interruptNode)
    .addNode("print", printNode)
    .addNode("feedback", feedbackNode)
    .addEdge(START, "chat")
    .addEdge("feedback", "chat")
    .addEdge("chat", "print")
    .addEdge("print", "interrupt")
    .addConditionalEdges("interrupt", (state) => {
      if (state.pending_input === "yes") {
        return END;
      } else if (state.pending_input === "no") {
        return "feedback";
      }
      return END;
    });
}

export default async function main() {
  const rl = createInterface({
    input: process.stdin,
    output: process.stdout,
  });

  const builder = await getGraphBuilder(rl);
  const memory = new MemorySaver();

  const graph = builder.compile({ checkpointer: memory });
  const thread_id = `thread-demo`;

  console.log(
    "ğŸ¤– æ¬¢è¿æ¥åˆ° LangGraph CLI Chatã€‚è¾“å…¥ä½ çš„é—®é¢˜ (è¾“å…¥ 'exit' é€€å‡º)ï¼š\n"
  );

  let userMessage;
  while (true) {
    const input = await new Promise<string>((resolve) => {
      rl.question("ä½ ï¼š", resolve);
    });

    if (input.toLowerCase() === "exit") {
      break;
    }

    userMessage = new HumanMessage(input);
    await graph.invoke(
      { messages: [userMessage] },
      { configurable: { thread_id } }
    );
  }

  rl.close();
  console.log("\nğŸ“œ ä¼šè¯ç»“æŸï¼Œå†è§ï¼");

  const history = [];
  for await (const config of memory.list({ configurable: { thread_id } })) {
    const state = await graph.getState(config);
    if (state?.config?.metadata?.writes) {
      history.push(state?.config?.metadata?.writes);
    }
  }

  if (history.length > 0) {
    console.log("\nğŸ”„ å¼€å§‹é‡ç°å¯¹è¯è·¯å¾„...");
    history.reverse().forEach((item, index) => {
      const [node, value] = Object.entries(item)[0];
      console.log(`---- æ­¥éª¤ ${index + 1} ----\n`);
      console.log(`èŠ‚ç‚¹ï¼š${node}\n`);
      console.log(
        `èŠ‚ç‚¹çŠ¶æ€ï¼š${JSON.stringify(
          {
            ...(value as Object),
            messages: value?.messages?.map((message) => ({
              type: message.constructor.name, // e.g., "HumanMessage", "AIMessage"
              content: message.content,
              role: "role" in message ? message.role : undefined, // if applicable
            })),
          },
          null,
          2
        )}\n`
      );
    });
  }
}
